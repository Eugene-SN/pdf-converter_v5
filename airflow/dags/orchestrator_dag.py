#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô Orchestrator DAG v4.0 - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è —ç—Ç–∞–ø–æ–≤
–£—Å—Ç—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–µ—Ä–µ–¥–∞—á–µ–π –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏ –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator, ShortCircuitOperator
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.exceptions import AirflowException
from typing import Dict, Any, Optional, List
import os
import json
import logging
import time
import glob
from pathlib import Path
# –£—Ç–∏–ª–∏—Ç—ã
from shared_utils import (
    SharedUtils, NotificationUtils, ConfigUtils,
    MetricsUtils, ErrorHandlingUtils
)
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è DAG
DEFAULT_ARGS = {
    'owner': 'pdf-converter',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}
# ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–Ω–∏–µ Master DAG —Å –Ω–∞—Ç–∏–≤–Ω—ã–º —Ä–µ–Ω–¥–µ—Ä–æ–º —à–∞–±–ª–æ–Ω–æ–≤
dag = DAG(
    'orchestrator_dag',
    default_args=DEFAULT_ARGS,
    description='‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô Orchestrator v4.0 - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ PDF –∫–æ–Ω–≤–µ–π–µ—Ä–∞',
    schedule_interval=None, # –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–æ API
    max_active_runs=3,
    catchup=False,
    tags=['pdf-converter', 'orchestrator', 'master-dag', 'v4', 'fixed'],
    render_template_as_native_obj=True # ‚úÖ –ö–†–ò–¢–ò–ß–ù–û: –ù–∞—Ç–∏–≤–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä —à–∞–±–ª–æ–Ω–æ–≤
)
# ===============================================================================
# –§–£–ù–ö–¶–ò–ò –û–†–ö–ï–°–¢–†–ê–¶–ò–ò
# ===============================================================================
def validate_orchestrator_input(**context) -> Dict[str, Any]:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã"""
    start_time = time.time()
    try:
        dag_run_conf = context['dag_run'].conf or {}
        logger.info(f"üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: {json.dumps(dag_run_conf, indent=2, ensure_ascii=False)}")
        required_params = ['input_file', 'filename', 'timestamp']
        missing_params = [param for param in required_params if not dag_run_conf.get(param)]
        if missing_params:
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {missing_params}")
        # ‚úÖ –ù–û–í–û–ï: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏ —Ñ–∞–π–ª–∞ –æ—Ç —Ö–æ—Å—Ç–æ–≤–æ–≥–æ –∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–Ω–æ–º—É
        input_file = dag_run_conf['input_file']
        if isinstance(input_file, str) and input_file.startswith('/mnt/storage/apps/pdf-converter/'):
            input_file = input_file.replace('/mnt/storage/apps/pdf-converter/', '/app/', 1)
        dag_run_conf['input_file'] = input_file
        if not SharedUtils.validate_input_file(input_file):
            raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_file}")
        stage_mode = dag_run_conf.get('stage_mode', 'full_conversion_with_validation')
        target_language = dag_run_conf.get('target_language', 'original')
        enable_ocr = bool(dag_run_conf.get('enable_ocr', False))
        if dag_run_conf.get('enable_ocr') is None:
            logger.info('OCR flag not provided; defaulting to disabled for digital PDFs')

        master_config = {
            'input_file': input_file,
            'filename': dag_run_conf['filename'],
            'target_language': target_language,
            'quality_level': dag_run_conf.get('quality_level', 'high'),
            'enable_ocr': enable_ocr,
            'preserve_structure': dag_run_conf.get('preserve_structure', True),
            'extract_tables': dag_run_conf.get('extract_tables', True),
            'extract_images': dag_run_conf.get('extract_images', True),
            'preserve_technical_terms': dag_run_conf.get('preserve_technical_terms', True),
            'chinese_document': dag_run_conf.get('chinese_document', True),
            'timestamp': dag_run_conf['timestamp'],
            'master_run_id': context['dag_run'].run_id,
            'pipeline_version': '4.0_fixed',
            'processing_start_time': datetime.now().isoformat(),
            'stage_mode': stage_mode,
            'processing_stages': dag_run_conf.get('processing_stages', 4),
            'validation_enabled': dag_run_conf.get('validation_enabled', True),
            'quality_target': dag_run_conf.get('quality_target', 95.0),
            'translation_required': target_language not in ['original', 'zh', 'zh-CN'],
            'input_dir': '/app/input',
            'output_zh_dir': '/app/output/zh',
            'output_target_dir': f"/app/output/{target_language}" if target_language not in ['original', 'zh'] else '/app/output/zh',
            'container_temp_dir': '/opt/airflow/temp',
        }
        MetricsUtils.record_processing_metrics(
            dag_id='orchestrator_dag',
            task_id='validate_orchestrator_input',
            processing_time=time.time() - start_time,
            success=True
        )
        logger.info(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Ñ–∞–π–ª–∞: {dag_run_conf['filename']}")
        logger.info(f"üéØ –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: {stage_mode}, –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫: {target_language}")
        return master_config
    except Exception as e:
        MetricsUtils.record_processing_metrics(
            dag_id='orchestrator_dag',
            task_id='validate_orchestrator_input',
            processing_time=time.time() - start_time,
            success=False
        )
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise
def prepare_stage1_config(**context) -> Dict[str, Any]:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è Stage 1"""
    try:
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        stage1_config = {
            'input_file': master_config['input_file'],
            'filename': master_config['filename'],
            'enable_ocr': master_config['enable_ocr'],
            'preserve_structure': master_config['preserve_structure'],
            'extract_tables': master_config['extract_tables'],
            'extract_images': master_config['extract_images'],
            'chinese_document': master_config['chinese_document'],
            'quality_level': master_config['quality_level'],
            'timestamp': master_config['timestamp'],
            'master_run_id': master_config['master_run_id'],
            'language': 'zh-CN',
            'chinese_optimization': True,
            'processing_timeout': 1800,
            'pipeline_version': '4.0_fixed',
            'processing_mode': 'chinese_optimized',
            'output_mode': 'orchestrated',
            'temp_base_dir': master_config['container_temp_dir'],
        }
        logger.info(f"üöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –∑–∞–ø—É—Å–∫ Stage 1: Document Preprocessing")
        return stage1_config
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ Stage 1: {e}")
        raise
def check_stage1_completion(**context) -> Dict[str, Any]:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Stage 1 —Å bridge-—Ñ–∞–π–ª–∞–º–∏"""
    try:
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        timestamp = master_config['timestamp']
        airflow_temp = os.getenv('AIRFLOW_TEMP_DIR', os.path.join(os.getenv('AIRFLOW_HOME', '/opt/airflow'), 'temp'))
        bridge_file = os.path.join(airflow_temp, f"stage1_bridge_{timestamp}.json")
        intermediate_file = None
        if os.path.exists(bridge_file):
            try:
                with open(bridge_file, 'r', encoding='utf-8') as f:
                    bridge_data = json.load(f)
                intermediate_file = bridge_data.get('intermediate_file') or bridge_data.get('docling_intermediate')
            except Exception:
                intermediate_file = None
        if not intermediate_file:
            patterns = [
                os.path.join(airflow_temp, f"*{timestamp}*intermediate.json"),
                os.path.join(airflow_temp, f"doc_*_intermediate.json"),
            ]
            for pattern in patterns:
                found = glob.glob(pattern)
                if found:
                    intermediate_file = found
                    break
        if not intermediate_file or not os.path.exists(intermediate_file):
            raise AirflowException(f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª Stage 1 –Ω–µ –Ω–∞–π–¥–µ–Ω (ts={timestamp}); –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–º temp –∏ –ø—É—Ç–∏")
        try:
            with open(intermediate_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if not data or 'title' not in data:
                logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª {intermediate_file} —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª {intermediate_file}: {e}")
            raise AirflowException(f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ñ–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω: {e}")
        stage1_completion = {
            'intermediate_file': intermediate_file,
            'stage1_completed': True,
            'ready_for_transformation': True,
            'original_config': master_config,
            'completion_time': datetime.now().isoformat(),
            'data_validation': 'passed',
        }
        logger.info(f"‚úÖ Stage 1 –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ, –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è Stage 2")
        return stage1_completion
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Stage 1: {e}")
        raise
def prepare_stage2_config(**context) -> Dict[str, Any]:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è Stage 2 —Å –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–º –ø—É—Ç–µ–º"""
    try:
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        stage1_result = context['task_instance'].xcom_pull(task_ids='check_stage1_completion')
        stage2_config = {
            'intermediate_file': stage1_result['intermediate_file'],
            'original_config': master_config,
            'stage1_completed': True,
            'ready_for_transformation': True,
            'chinese_document': master_config['chinese_document'],
            'preserve_technical_terms': master_config['preserve_technical_terms'],
            'transformation_method': 'chinese_optimized_v4',
            'quality_level': master_config['quality_level'],
            'pipeline_version': '4.0_fixed',
            'output_mode': 'orchestrated',
            'timestamp': master_config['timestamp'],
            'filename': master_config['filename'],
        }
        logger.info(f"üöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –∑–∞–ø—É—Å–∫ Stage 2: Content Transformation")
        return stage2_config
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ Stage 2: {e}")
        raise
def check_stage2_completion(**context) -> Dict[str, Any]:
    """‚úÖ –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Stage 2"""
    try:
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        timestamp = master_config['timestamp']
        filename = master_config['filename']
        expected_md_file = f"/app/output/zh/{timestamp}_{filename.replace('.pdf', '.md')}"
        host_md_file = f"{master_config['output_zh_dir']}/{timestamp}_{filename.replace('.pdf', '.md')}"
        fallback_md_file = f"/opt/airflow/output/zh/{timestamp}_{filename.replace('.pdf', '.md')}"
        md_file_path = None
        for path in [expected_md_file, host_md_file, fallback_md_file]:
            if os.path.exists(path):
                md_file_path = path
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω MD —Ñ–∞–π–ª: {path}")
                break
        if not md_file_path:
            patterns = [
                f"/app/output/zh/*{timestamp}*.md",
                f"{master_config['output_zh_dir']}/*{timestamp}*.md",
                f"/app/output/zh/{filename.replace('.pdf', '.md')}",
                f"{master_config['output_zh_dir']}/{filename.replace('.pdf', '.md')}",
                f"/opt/airflow/output/zh/*{timestamp}*.md",
                f"/opt/airflow/output/zh/{filename.replace('.pdf', '.md')}",
            ]
            for pattern in patterns:
                files = glob.glob(pattern)
                if files:
                    md_file_path = files
                    break
        if not md_file_path:
            raise AirflowException(f"‚ùå MD —Ñ–∞–π–ª –¥–ª—è {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        stage2_completion = {
            'markdown_file': md_file_path,
            'stage2_completed': True,
            'ready_for_translation': master_config['translation_required'],
            'original_config': master_config,
            'completion_time': datetime.now().isoformat(),
        }
        logger.info(f"‚úÖ Stage 2 –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ: {md_file_path}")
        return stage2_completion
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Stage 2: {e}")
        raise
def prepare_stage3_config(**context) -> Dict[str, Any]:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è Stage 3 (Translation)"""
    try:
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        stage2_result = context['task_instance'].xcom_pull(task_ids='check_stage2_completion')
        if not master_config['translation_required']:
            logger.info("üîÑ –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º Stage 3")
            return {'skip_stage3': True}
        stage3_config = {
            'markdown_file': stage2_result['markdown_file'],
            'original_config': master_config,
            'stage2_completed': True,
            'target_language': master_config['target_language'],
            'preserve_technical_terms': master_config['preserve_technical_terms'],
            'chinese_source': True,
            'translation_method': 'builtin_dictionary_v4',
            'pipeline_version': '4.0_fixed',
            'output_mode': 'orchestrated',
        }
        logger.info(f"üöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –∑–∞–ø—É—Å–∫ Stage 3: Translation ‚Üí {master_config['target_language']}")
        return stage3_config
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ Stage 3: {e}")
        raise
def prepare_stage4_config(**context) -> Dict[str, Any]:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è Stage 4 (QA)"""
    try:
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        if master_config['translation_required']:
            translated_file = f"{master_config['output_target_dir']}/{master_config['timestamp']}_{master_config['filename'].replace('.pdf', '.md')}"
        else:
            stage2_result = context['task_instance'].xcom_pull(task_ids='check_stage2_completion')
            translated_file = stage2_result['markdown_file']
        document_id = master_config.get(
            'document_id',
            f"{master_config['timestamp']}_{master_config['filename'].replace('.pdf', '')}"
        )

        stage4_config = {
            'translated_file': translated_file,
            'original_config': master_config,
            'stage3_completed': not master_config['translation_required'] or True,
            'target_language': master_config['target_language'],
            'quality_target': master_config['quality_target'],
            'auto_correction': master_config.get('auto_correction', True),
            'validation_levels': 5,
            'validation_mode': 'content_with_structure',
            'pipeline_version': '4.0_fixed',
            'original_pdf_path': master_config['input_file'],
            'document_id': document_id,
        }
        logger.info(f"üöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –∑–∞–ø—É—Å–∫ Stage 4: Quality Assurance")
        return stage4_config
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ Stage 4: {e}")
        raise
def finalize_orchestration(**context) -> Dict[str, Any]:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    try:
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        start_time = datetime.fromisoformat(master_config['processing_start_time'])
        end_time = datetime.now()
        processing_duration = end_time - start_time
        final_output_path = None
        if master_config['translation_required']:
            final_output_path = f"{master_config['output_target_dir']}/{master_config['timestamp']}_{master_config['filename'].replace('.pdf', '.md')}"
        else:
            final_output_path = f"{master_config['output_zh_dir']}/{master_config['timestamp']}_{master_config['filename'].replace('.pdf', '.md')}"
        orchestration_result = {
            'master_run_id': master_config['master_run_id'],
            'processing_completed': True,
            'total_processing_time': str(processing_duration),
            'processing_duration_seconds': processing_duration.total_seconds(),
            'source_file': master_config['input_file'],
            'filename': master_config['filename'],
            'target_language': master_config['target_language'],
            'final_output_path': final_output_path,
            'qa_report_path': f"/app/temp/qa_report_{master_config['timestamp']}.json",
            'pipeline_stages_completed': master_config['processing_stages'],
            'orchestrator_version': '4.0_fixed',
            'chinese_document_optimized': master_config['chinese_document'],
            'translation_performed': master_config['translation_required'],
            'success': True,
            'processing_stats': {
                'ocr_used': master_config['enable_ocr'],
                'technical_terms_preserved': master_config['preserve_technical_terms'],
                'target_language': master_config['target_language'],
                'quality_level': master_config['quality_level'],
                'stage_mode': master_config['stage_mode'],
            },
        }
        logger.info(f"üéØ –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞ {processing_duration}")
        return orchestration_result
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        raise
def notify_orchestrator_completion(**context) -> None:
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –§–∏–Ω–∞–ª—å–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ"""
    try:
        orchestration_result = context['task_instance'].xcom_pull(task_ids='finalize_orchestration')
        master_config = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
        success = orchestration_result['success']
        processing_time = orchestration_result['total_processing_time']
        filename = master_config['filename']
        target_language = master_config['target_language']
        if success:
            message = f"""
üéâ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô PDF –ö–û–ù–í–ï–ô–ï–† v4.0 –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!
üìÑ –§–∞–π–ª: {filename}
üåê –Ø–∑—ã–∫: {target_language}
‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time}
üîÑ –í–´–ü–û–õ–ù–ï–ù–ù–´–ï –≠–¢–ê–ü–´:
‚úÖ Stage 1: Document Preprocessing (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞)
‚úÖ Stage 2: Content Transformation (–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ MD)
{'‚úÖ Stage 3: Translation Pipeline (–ø–µ—Ä–µ–≤–æ–¥)' if orchestration_result['translation_performed'] else '‚è≠Ô∏è Stage 3: –ü—Ä–æ–ø—É—â–µ–Ω (–ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è)'}
‚úÖ Stage 4: Quality Assurance (–≤–∞–ª–∏–¥–∞—Ü–∏—è)
üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: ‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–∞
- –ö–∏—Ç–∞–π—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã: ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã
- –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: {orchestration_result['final_output_path']}
- QA –æ—Ç—á–µ—Ç: {orchestration_result['qa_report_path']}
üöÄ –°–ò–°–¢–ï–ú–ê v4.0 –ò–°–ü–†–ê–í–õ–ï–ù–ê –ò –ì–û–¢–û–í–ê –ö –†–ê–ë–û–¢–ï!
"""
        else:
            message = f"""
‚ùå –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô PDF –ö–û–ù–í–ï–ô–ï–† v4.0 –ó–ê–í–ï–†–®–ï–ù –° –û–®–ò–ë–ö–ê–ú–ò
üìÑ –§–∞–π–ª: {filename}
‚è±Ô∏è –í—Ä–µ–º—è –¥–æ –æ—à–∏–±–∫–∏: {processing_time}
–¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º—ã.
"""
        logger.info(message)
        if success:
            NotificationUtils.send_success_notification(context, orchestration_result)
        else:
            NotificationUtils.send_failure_notification(context, Exception("Pipeline failed"))
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")
# ===============================================================================
# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–ê–î–ê–ß
# ===============================================================================
validate_input = PythonOperator(
    task_id='validate_orchestrator_input',
    python_callable=validate_orchestrator_input,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)
prepare_stage1 = PythonOperator(
    task_id='prepare_stage1_config',
    python_callable=prepare_stage1_config,
    execution_timeout=timedelta(minutes=2),
    dag=dag
)
trigger_stage1 = TriggerDagRunOperator(
    task_id='trigger_stage1_preprocessing',
    trigger_dag_id='document_preprocessing',
    conf="{{ task_instance.xcom_pull(task_ids='prepare_stage1_config') | tojson }}",
    wait_for_completion=True,
    poke_interval=30,
    allowed_states=['success'],
    execution_timeout=timedelta(minutes=45),
    dag=dag
)
check_stage1 = PythonOperator(
    task_id='check_stage1_completion',
    python_callable=check_stage1_completion,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)
prepare_stage2 = PythonOperator(
    task_id='prepare_stage2_config',
    python_callable=prepare_stage2_config,
    execution_timeout=timedelta(minutes=2),
    dag=dag
)
trigger_stage2 = TriggerDagRunOperator(
    task_id='trigger_stage2_transformation',
    trigger_dag_id='content_transformation',
    conf="{{ task_instance.xcom_pull(task_ids='prepare_stage2_config') | tojson }}",
    wait_for_completion=True,
    poke_interval=30,
    allowed_states=['success'],
    execution_timeout=timedelta(minutes=30),
    dag=dag
)
check_stage2 = PythonOperator(
    task_id='check_stage2_completion',
    python_callable=check_stage2_completion,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)
prepare_stage3 = PythonOperator(
    task_id='prepare_stage3_config',
    python_callable=prepare_stage3_config,
    execution_timeout=timedelta(minutes=2),
    dag=dag
)
trigger_stage3 = TriggerDagRunOperator(
    task_id='trigger_stage3_translation',
    trigger_dag_id='translation_pipeline',
    conf="{{ task_instance.xcom_pull(task_ids='prepare_stage3_config') | tojson }}",
    wait_for_completion=True,
    poke_interval=30,
    allowed_states=['success'],
    execution_timeout=timedelta(minutes=30),
    dag=dag
)
prepare_stage4 = PythonOperator(
    task_id='prepare_stage4_config',
    python_callable=prepare_stage4_config,
    execution_timeout=timedelta(minutes=2),
    dag=dag
)
trigger_stage4 = TriggerDagRunOperator(
    task_id='trigger_stage4_quality_assurance',
    trigger_dag_id='quality_assurance',
    conf="{{ task_instance.xcom_pull(task_ids='prepare_stage4_config') | tojson }}",
    wait_for_completion=True,
    poke_interval=30,
    allowed_states=['success'],
    execution_timeout=timedelta(minutes=20),
    dag=dag
)
finalize_orchestrator = PythonOperator(
    task_id='finalize_orchestration',
    python_callable=finalize_orchestration,
    execution_timeout=timedelta(minutes=5),
    dag=dag
)
notify_completion = PythonOperator(
    task_id='notify_orchestrator_completion',
    python_callable=notify_orchestrator_completion,
    trigger_rule='all_done',
    execution_timeout=timedelta(minutes=3),
    dag=dag
)
# ===============================================================================
# –£–°–õ–û–í–ù–û–ï –í–´–ü–û–õ–ù–ï–ù–ò–ï STAGE 3 (–î–û–ü–û–õ–ù–ï–ù–û)
# ===============================================================================
def _should_translate(**context) -> bool:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –∏–Ω–∞—á–µ False (ShortCircuit)."""
    mc = context['task_instance'].xcom_pull(task_ids='validate_orchestrator_input')
    return bool(mc.get('translation_required'))
should_translate = ShortCircuitOperator(
    task_id='should_translate',
    python_callable=_should_translate,
    ignore_downstream_trigger_rules=False,
    dag=dag,
)
# –í–µ—Ç–≤–ª–µ–Ω–∏–µ: –∑–∞–ø—É—Å–∫ Stage 3 —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥–∞
prepare_stage3 >> should_translate >> trigger_stage3
# –†–∞–∑—Ä–µ—à–∏—Ç—å Stage 4 –∏–¥—Ç–∏ –æ—Ç Stage 2 (–∏ —É—á–∏—Ç—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç Stage 3, –µ—Å–ª–∏ –æ–Ω –±—ã–ª)
from airflow.utils.trigger_rule import TriggerRule
prepare_stage4.trigger_rule = TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS
prepare_stage4.set_upstream(check_stage2)
prepare_stage4.set_upstream(trigger_stage3)
# ===============================================================================
# –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô
# ===============================================================================
(validate_input >> prepare_stage1 >> trigger_stage1 >> check_stage1 >>
 prepare_stage2 >> trigger_stage2 >> check_stage2 >>
 prepare_stage3 >>
 prepare_stage4 >> trigger_stage4 >>
 finalize_orchestrator >> notify_completion)
# ===============================================================================
# –û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö...
# ===============================================================================
def handle_orchestrator_failure(context):
    """‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    try:
        failed_task = context['task_instance'].task_id
        master_config = context.get('dag_run', {}).conf or {}
        exception = context.get('exception')
        error_message = f"""
üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ú –û–†–ö–ï–°–¢–†–ê–¢–û–†–ï v4.0
–ó–∞–¥–∞—á–∞: {failed_task}
–§–∞–π–ª: {master_config.get('filename', 'unknown')}
–û—à–∏–±–∫–∞: {str(exception) if exception else 'Unknown error'}

–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–û –ó–ê–î–ê–ß–ê–ú:
- validate_orchestrator_input: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
- check_stage1_completion: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
- check_stage2_completion: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ MD —Ñ–∞–π–ª–æ–≤
- trigger_stage*: –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö DAG

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–°–¢–†–ê–ù–ï–ù–ò–Æ:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–∞–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ volumes –≤ docker-compose.yml
2. –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—É—Ç–µ–π —Ñ–∞–π–ª–æ–≤
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä v4.0 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–µ—Ä–µ–¥–∞—á—É –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏.
"""
        logger.error(error_message)
        NotificationUtils.send_failure_notification(context, exception)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –æ—à–∏–±–æ–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: {e}")
for task in dag.tasks:
    task.on_failure_callback = handle_orchestrator_failure
